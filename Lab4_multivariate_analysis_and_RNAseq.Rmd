---
title: "Lab 4: Multivariate Analysis and RNA-Seq"
author: "Bios 221: Modern Statistics for Modern Biology"
date: "Oct. 2023"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup1, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


In this lab, we will learn the basics of Multivariate Analysis and RNA-Seq high-throughput sequencing.

Work through this lab by running all the R code to your computer and making sure 
that you understand the input and the output. Make alterations where you see
fit. We encourage you to work through  this lab with a partner. 

Once you get to the end of this lab, go to [Canvas](https://canvas.stanford.edu) 
to submit your answer to the quiz questions dispersed throughout this lab.
Some questions will be open-ended and you will not see them appear
on Canvas.

Please do not provide more information than the answers requested as Canvas expects
compact, precise answers.


# Multivariate analysis

## Goal

In this section we will learn the how to do PCA and some Multivariate Analysis using a few examples. 

We start by making sure we have all the packages needed for the Lab installed on our machine.

```{r setup2, warning=FALSE, message=FALSE, results='hide'}
knitr::opts_chunk$set(echo = TRUE)
pkgs_needed = c("tidyverse","GGally", "factoextra", "ade4", "genefilter",
                  "pheatmap", "hexbin",
                 "DESeq2", "pasilla","TENxPBMCData","apeglm")
BiocManager::install(setdiff(pkgs_needed, installed.packages()))
library("tidyverse")
```



## Loading the  Data 

In the first part of this lab, we will be working with the following two  datasets:

```{r}
turtles = read.table(url("https://web.stanford.edu/class/bios221/data/PaintedTurtles.txt"), header=TRUE)
head(turtles)
```

```{r}
download.file(url = "https://web.stanford.edu/class/bios221/data/athletes.RData",
              destfile = "athletes.RData",mode = "wb")
load("athletes.RData")
athletes[1:3,]
```

## Low dimensional data summaries and preparation

It is instructive to first consider 2-dimensional summaries of the datasets:

```{r}
library("GGally")
ggpairs(turtles[,-1], axisLabels="none")
```

Can you do the same for the athletes data?

```{r}
# TODO
```

Correlations can be displayed on a color scale by a simple call to the `pheatmap` function:

```{r heatmapathletes}
library("pheatmap")
pheatmap(cor(athletes),cell.width=10,cell.height=10)
```

## Preprocessing the data

Our first task in data analysis is to transform the data: standardizing the data 
to a common standard deviation. This rescaling is done using the `scale` 
function which makes every column have a variance of 1 (and also mean 0).

```{r turtlesDim12}
scaledTurtles=data.frame(scale(turtles[,-1]),sex=turtles[,1])
ggplot(scaledTurtles,aes(x=width,y=height, group =sex)) +
  geom_point(aes(color=sex))
```

Can you compute the standard deviation and mean of each column in the `turtles`
data frame? Can you do the same on the scaled dataset, i.e. on `scaledturtles`?

**Quiz question 1**: What was the mean of turtles' heights before standardizing?

**Quiz question 2**: What was the standard deviation of turtles' widths before standardizing?

**Quiz question 3**: What was the standard deviation of turtles' widths after standardizing?


```{r}
# TODO
```


## PCA

```{r}
library("ggplot2")
athletes = scale(athletes)
n = nrow(athletes)
athletes = data.frame(athletes)
```

```{r SimpleScatter}
p = ggplot(athletes, aes(x = weight,y=  disc)) +
  geom_point(size = 2, shape=21)
p + geom_point(aes(y = rep(0, n)), colour="red") +
  geom_segment(aes(xend = weight, yend = rep(0,n)), linetype = "dashed")
```

Now try to do the following:

**Quiz question 4**: Calculate the variance of the red points in the above
figure. (points are projected onto the weight-axis).

**Quiz question 5**: Make a similar plot showing projection lines onto the y 
axis and show projected points in blue. What is the variance of the projected 
points now?

### Summarize 2D-data by a line

We regress `disc` on `weight` with the `lm` function (linear model) to find the regression line; its slope (a) is given by the second coefficient in the output of `lm` and its intercept (b) is the first:

```{r Reg1}
reg1 = lm(disc ~ weight,data = athletes)
a = reg1$coefficients[1] # Intercept
b = reg1$coefficients[2] # slope
pline = p + geom_abline(intercept = a, slope = b, col = "blue", lwd = 1.5)
pline + geom_segment(aes(xend = weight, yend = reg1$fitted),
                     colour = "red", arrow = arrow(length = unit(0.15,"cm")))
```

Can you regress `weight` on `discs` and generate a similar plot? 

```{r}
# TODO
```

Can you create a plot that shows all points, as well as both regression lines, i.e., a plot that show both the line you get from `lm(disc ~ weight)` and `lm(weight ~ disc)`?

```{r}
# TODO
```

Now we will plot the line chosen to minimize the sum of squares of the orthogonal (perpendicular) projections of data points onto it; we call this the principal component line.

```{r PCAmin}
X = cbind(athletes$disc, athletes$weight)
svda = svd(X)
pc = X %*% svda$v[, 1] %*% t(svda$v[, 1])
bp = svda$v[2, 1] / svda$v[1, 1]
ap = mean(pc[, 2]) - bp * mean(pc[, 1])

p + geom_segment(xend = pc[,1], yend = pc[,2]) + 
  geom_abline(intercept = ap, slope = bp, col = "purple", lwd = 1.5) + 
  coord_fixed()
```

Can you create a plot that includes both the line from the plot above, plus the two regression lines `lm(disc ~ weight)` and `lm(weight ~ disc)`?

```{r}
#TODO
```


If we rotate the `(discus, weight)` plane with this change of coordinates making the purple line the horizontal $x$ axis, we obtain what is know as the first principal plane:

```{r CompareSDs}
ppdf = data.frame(PC1n = -svda$u[,1]*svda$d[1], PC2n=svda$u[,2] * svda$d[2])

ggplot(ppdf,aes(x = PC1n, y=PC2n)) + geom_point() + ylab("PC2 ") +
  geom_hline(yintercept = 0, color = "purple", lwd = 1.5, alpha = 0.5) +
  geom_point(aes(x = PC1n, y = 0),color = "red") + xlab("PC1 ")+
  xlim(-3.5, 2.7)+ylim(-2, 2) + coord_fixed() +
  geom_segment(aes(xend = PC1n,yend = 0), color = "red")
```

**Quiz question 6**: What are the sums of squares of the red segments equal to?

**Quiz question 7**: What is the variance of this new set of red points?

**Quiz question 8**: What is the sum of the variances of `ppdf$PC1n` and `ppdf$PC2n`?

We could have gotten the same results using the `princomp` command as follows:

```{r}
pca_athletes = princomp(X)
```

Now compare (note that e.g. loadings are not unique up to sign, but the lines they define are the same):

```{r}
svda$v
pca_athletes$loadings
```

```{r}
head(pca_athletes$scores)
```

```{r}
head(svda$u %*% diag(svda$d))
```

**Quiz question 9**: Which field in `pca_athletes` contains approximately the same object as `c(sd(ppdf$PC1n), sd(ppdf$PC2n))`? 

**Quiz question 10**: Unfortunately the results stored in the above field do not perfectly match  `c(sd(ppdf$PC1n), sd(ppdf$PC2n))`. If you multiply by which correction factor will you get the results to match `c(sd(ppdf$PC1n), sd(ppdf$PC2n))`?

The difference is that ``princomp`` returns unbiased estimates of sample standard deviations.

### Turtle PCA

Now let's continue inspecting the turtles data.

```{r PCAturtlesunscaled}
turtles3var = turtles[, -1]
apply(turtles3var, 2, mean)
```

We start by looking at the variances of the three components in the **un**standardized case:

```{r simplecomp}
apply(turtles3var, 2, var)
```

Next we see that basically all 3 variables are very strongly correlated:

```{r PCAturtles}
turtlesc = scale(turtles3var)
cor(turtlesc)
```

Because of the strong correlations, we would expect that the data matrix can be well approximated by a rank 1 matrix. Let's do the PCA:

```{r}
library("factoextra")
pca1 = princomp(turtlesc)
# or alternatively:
#pca1 = ade4::dudi.pca(turtlesc, scannf = FALSE)
pca1
fviz_eig(pca1, geom = "bar", width = 0.4)
```

The screeplot showing the eigenvalues for the standardized data: one very large component in this case and two very small ones. In this case the data are (almost) one dimensional.


**Quiz question 11**: What is the percentage of variance
explained by the first PC?

```{r}
# TODO
```

```{r turtlesplotvar}
fviz_pca_var(pca1, label = "var") +coord_fixed()
```


```{r turtlesbiplot}
fviz_pca_biplot(pca1, label = "var", col.ind = turtles[,1]) 
```


```{r turtlesplotindfixed}
fviz_pca_ind(pca1, col.ind = turtles[,1]) + coord_fixed() 
```


```{r turtlesplotind}
fviz_pca_ind(pca1, col.ind = turtles[,1]) 
```


Add ellipses for female and male groups to the plot above.

```{r}
# TODO
```


**Quiz question 12**: Did the males or female turtles tend to be larger?

### Back to the athletes

Now let us try to interpret another scree plot with more dimensions.

```{r}
library("ade4")
pca.ath = dudi.pca(athletes, scannf = FALSE)
pca.ath$eig
```

```{r}
fviz_eig(pca.ath, geom = "bar", bar_width = 0.3) + ggtitle("")
```

The screeplot make a clear drop after the second eigenvalue. This indicates a good approximation will be obtained at rank 2. Letâ€™s look at an interpretation of the first two axes by projecting the loadings of the original (old) variables as they project onto the two new ones.

```{r}
fviz_pca_var(pca.ath, col.circle = "black") + ggtitle("")
```

**Note**

It can seem paradoxical that the m variables are opposed to the others.

**Question (not on the quiz): Why does this occur?**

We can make the variables align and give the left direction on PCA 1 to
be an axis of athletic ability by changing the signs:

```{r}
athletes[, c(1, 5, 6, 10)] = -athletes[, c(1, 5, 6, 10)]
cor(athletes) %>% round(1)
```

```{r}
pcan.ath = dudi.pca(athletes, nf = 2, scannf = FALSE)
pcan.ath$eig
```

**Quiz Question 13**:  Changing the signs for some variables changes the variances explained by the PCs (True/False)?


```{r}
fviz_pca_var(pcan.ath, col.circle="black") + ggtitle("")
```

```{r}
fviz_pca_ind(pcan.ath) + ggtitle("") + ylim(c(-2.5,5.7))
```

What do you notice about the numbers labeling the points?


# RNA-Seq

## Goal

In this section, we will become more familiar with count data in RNA-Seq high-throughput
sequencing. We will see how tools developed during the lecture on hypothesis
testing can be applied to data from RNA-Seq experiments. We will model these read count data and evaluate how well our models model fit. We hope to detect and quantify systematic changes between 
conditions, compared to within-condition variability (which we consider noise).

## Load Packages needed for this section.


```{r warning=FALSE, message=FALSE}
library("tidyverse")
library("ggplot2")
library("DESeq2")
library("pasilla")
library("genefilter")
library("pheatmap")
library("MASS")
library("TENxPBMCData")
```

## Example dataset: the pasilla data

The ``pasilla`` data are from an experiment on Drosophila melanogaster cell
cultures that investigated the effect of RNAi knock-down of the splicing factor on the cells' transcriptome. 

We already quickly explored this dataset 
in our lab on Mixtures and variance stabilizing transformations.

```{r loadpas, results="hide", error=FALSE}
fn = system.file("extdata", "pasilla_gene_counts.tsv",
                  package = "pasilla", mustWork = TRUE)
counts = as.matrix(read.csv(fn, sep = "\t", row.names = "gene_id"))
```

The data are stored as a rectangular table in a tab-delimited file, which
we  read into the matrix ``counts``. 

```{r counts}
dim(counts)
counts[ 2000+(0:3), ]
```

When loading data from a file, a good plausibility check is to print out some of 
the data, and maybe not only at the very beginning, but also at some random 
point in the middle, as we have done above. The table is a matrix of integer 
values: the value in the $i$th row and the $j$th column of the matrix indicates 
how many reads have been mapped to gene $i$ in sample $j$.  

There were two experimental conditions, termed **untreated** and **treated** in 
the header of the count table that we loaded. They correspond to negative
control and to siRNA against ``pasilla``.  The experimental metadata of the 
`r ncol(counts)` samples in this dataset are provided in a spreadsheet-like 
table. Here, we use the function ``system.file`` to locate a file that is 
shipped together with the ``pasilla`` package. When you work with your own data, 
simply prepare and load the corresponding file, or use some other way to 
generate a dataframe like ``pasillaSampleAnno``.

```{r annotationFile}
annotationFile = system.file("extdata", "pasilla_sample_annotation.csv",
                             package = "pasilla", mustWork = TRUE)
pasillaSampleAnno = readr::read_csv(annotationFile)
pasillaSampleAnno
```

As we see here, the overall dataset was produced in two batches, the first one 
consisting of three sequencing libraries that were subjected to single-read 
sequencing, the second batch consisting of four libraries for which paired-end 
sequencing was used.  Let's convert the relevant columns of
``pasillaSampleAnno`` into factors, overriding the default level ordering 
(which is alphabetical) by one that makes more sense to us.

```{r factors}
pasillaSampleAnno = mutate(
  pasillaSampleAnno,
  condition = factor(condition, levels = c("untreated", "treated")),
  type      = factor(type, levels = c("single-read", "paired-end")))
```

The design is approximately balanced between the factor of interest, 
``condition``, and the nuisance factor ``type``. How can you check that? 
Use the ``table`` function.

```{r condvstype}
# TODO
```

We use the constructor function ``DESeqDataSetFromMatrix`` to create a
``DESeqDataSet`` from the matrix ``counts`` and the sample annotation dataframe
``pasillaSampleAnno``.

Note how in the code below, we have to put in extra work to match the column 
names of the ``counts`` object with the ``file`` column of the 
``pasillaSampleAnno`` dataframe, in particular, we need to remove the ``fb`` 
that happens to be used in the ``file`` column for some reason. Such data 
wrangling is very common. One of the reasons for storing the data in a 
``DESeqDataSet`` object is that we then no longer have to worry about such 
things.

```{r DESeq2, message = FALSE, warning = FALSE}
mt = match(colnames(counts), sub("fb$", "", pasillaSampleAnno$file))
pasilla = DESeqDataSetFromMatrix(
  countData = counts,
  colData   = pasillaSampleAnno[mt, ],
  design    = ~ condition)
class(pasilla)
is(pasilla, "SummarizedExperiment")
```

The ``SummarizedExperiment`` class --and therefore ``DESeqDataSet``-- also
contains facilities for storing annotation of the rows of the count matrix. 
For now, we are content with the gene identifiers from the row names of 
the ``counts`` table.


**Quiz Question 14**: When we constructed our `SummarizedExperiment` object, we 
also saved some column metadata which we had initially stored in 
`pasillaSampleAnno`. With which function can we extract this information again?
(Hint:`?SummarizedExperiment`)



We will now explore the mean-variance relationship for the biological replicates in the pasilla 
dataset using the ``log`` scale on both axes:


```{r countsvarmean, warning = FALSE}
library("ggplot2")
library("matrixStats")
library("hexbin")
sf = estimateSizeFactorsForMatrix(counts)
ncounts  = counts / matrix(sf, 
   byrow = TRUE, ncol = ncol(counts), nrow = nrow(counts))
uncounts = ncounts[, grep("^untreated", colnames(ncounts)), drop = FALSE]

p = ggplot(
  tibble(mean = apply(uncounts, 1, mean), var = apply(uncounts, 1, var)), 
         aes(x = log(mean), y = log(var))) +
  geom_hex() +
  coord_fixed() +
  geom_abline(slope = 1:2, color = c("forestgreen", "red"))
p
```


The green line (slope 1) is what we expect if the variance ($v$) equals the mean
($m$), as is the case for a Poisson-distributed random variable: $v=m$. We see 
that this approximately fits the data in the lower range.  The red line 
(slope 2) corresponds to the quadratic mean-variance relationship $v=m^2$; 
lines parallel to it (not shown) would represent $v = cm^2$ for various values
of $c$. We can see that in the upper range of the data, the quadratic 
relationship approximately fits the data, for some value of $c<1$.

## Size factors

In class we showed a plot comparing the slightly more refined method employed 
by DESeq2 for estimating size factors, compared to just summing the total number 
of counts in a sample across all genes. Let us directly do this:

```{r}
ggplot(tibble(
  `size factor` = estimateSizeFactorsForMatrix(counts),
  `sum` = colSums(counts)), aes(x = `size factor`, y = `sum`)) +
  geom_point()
```

## The DESeq2 method

After these preparations, we are now ready to jump straight into differential 
expression analysis. A choice of standard analysis steps are wrapped into a
single function, ``DESeq``.

```{r deseq}
pasilla = DESeq(pasilla)
```

The DESeq function is simply a wrapper that calls, in order, the functions 
``estimateSizeFactors``, ``estimateDispersions`` (dispersion estimation) and 
``nbinomWaldTest`` (hypothesis tests for differential abundance). You can
always call these functions individually if you want to modify their behavior
or interject custom steps. Let us look at the results.

```{r theresults}
res = results(pasilla)
res[order(res$padj), ] %>% head
```

The first step after a differential expression analysis is visualization of the
results.

### Histogram of p-values

```{r hist1, fig.width = 4.5, fig.height = 4.5}
ggplot(as(res, "data.frame"), aes(x = pvalue)) +
  geom_histogram(binwidth = 0.01, fill = "Royalblue", boundary = 0)
```

The distribution displays two main components: a uniform background with values 
between 0 and 1, and a peak of small p-values at the left.  The uniform 
background corresponds to the non-differentially expressed genes. Usually this 
is the majority of genes. The left hand peak corresponds to differentially 
bioexpressed genes.

The ratio of the level of the background to the height of the peak gives us 
a rough indication of the false discovery rate (FDR) that would be associated 
with calling the genes in the leftmost bin differentially expressed.

**Quiz Question 15**: What is the FDR (in %) for the leftmost bin (i.e. when
rejecting hypotheses smaller than 0.01)? The code snippet below might be a good 
starting point. Estimate the background level with the median bin count in the 
histogram object.

```{r hist2}
pv_hist <- hist(res$pvalue, breaks=seq(0,1, length=100), plot=FALSE)
```

Recall from class the we can use `p.adjust` function to conduct multiple testing 
directly on the p-values (and we reject the adjusted p-values $\leq \alpha$). 
Let us quickly extract the p-values and remove the NAs:

```{r}
pvals <- na.omit(res$pvalue)
```


**Quiz Question 16**: How many hypotheses do you reject with Benjamini-Hochberg 
at a FDR of 0.1?

**Quiz Question 17**: How many hypotheses do you reject with Bonferroni at a 
FWER of 0.1?

You might notice that your answer to 3 is different than what the adjusted
p-values in `res$padj` might imply; the reason is that internally DESeq2 
uses a more advanced method to do the FDR correction compared to 
Benjamini-Hochberg (a simplified variant of IHW in which low counts genes get 
filtered out). 

As mentioned in the testing class, we can use the p-value histogram plot for
diagnostic purposes. Let's look at a simulation to understand this point. 
First, we simulate four samples under the null (same mean and variance) and 
apply t-tests:

```{r uniform_hist}
set.seed(0xdada2)
y = cbind(rnorm(10000, 0, 1),
          rnorm(10000, 0, 1),
          rnorm(10000, 0, 1),
          rnorm(10000, 0, 1))
library(genefilter)
pvalue = rowttests(y, factor(c("C","C","T","T")))$p.value
ggplot(tibble(pvalue), aes(x = pvalue)) +
  geom_histogram(binwidth = 0.01, fill = "Royalblue", boundary = 0)
```

Looks good. But now assume that two samples were processed on the same day 
separately from the others. That day, something happened and the means in both 
samples were shifted. In that case, the histogram is skewed to the right. 

Now try to modify the following code by shifting the mean of the second and 
fourth sample by two?

```{r skewed_hist, fig.width = 4.5, fig.height = 4.5}
# TODO
#set.seed(0xdada2)
#y = cbind(rnorm(10000, ?, 1),
#          rnorm(10000, ?, 1),
#          rnorm(10000, ?, 1),
#          rnorm(10000, ?, 1))
#pvalue = rowttests(y, factor(c("C","C","T","T")))$p.value
#ggplot(tibble(pvalue), aes(x = pvalue)) +
#  geom_histogram(binwidth = 0.01, fill = "Royalblue", boundary = 0)
```

One way to take such batch effects into account is by adding the batch factor 
(e.g. the run day) in our model. 

What can you do if you suspect there are ``hidden'' factors that affect your 
data, but they are not documented? (Sometimes, such unknown/undocumented 
covariates are also called batch effects.) There are methods that try to 
identify blocking factors in an unsupervised fashion, see e.\,g., 
[Leek and Storey 2007](http://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.0030161) 
or [Stegle et al 2010](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000770).

### MA plot

Read the Wikipedia description for [MA plots](https://en.wikipedia.org/wiki/MA_plot). 
Fold change versus mean of size-factor normalized counts. Logarithmic scaling
is used for both axes. By default, points are colored blue if the adjusted 
p-value is less than 0.1. Points which fall out of the y -axis range are 
plotted as triangles.

To produce the MA plot, we can use the function ``plotMA`` in the ``DESeq2`` 
package.

```{r MA}
plotMA(pasilla, ylim = c( -2, 2))
```

But as mentioned in class, we can often do better with Empirical Bayes shrinkage 
of the counts. We can achieve this with a newer method, called "apeglm", as 
follows:
  
```{r}
lfc_shrink_res <- lfcShrink(pasilla, coef="condition_treated_vs_untreated", type="apeglm")
```

```{r MA shrink, fig.width = 3, fig.height = 3}
plotMA(lfc_shrink_res, ylim = c( -2, 2))
```


### PCA plot

To produce a planar plot, we can use the ``DESeq2`` function ``plotPCA`` 
after first transforming the data with the rlog transformation.

```{r PCArlog}
pas_rlog = rlogTransformation(pasilla)
```

```{r PCAplot, fig.width = 4, fig.height = 3.2}
plotPCA(pas_rlog, intgroup=c("condition", "type")) + coord_fixed()
```

This type of plot is useful for visualizing the overall effect of experimental 
covariates and/or to detect batch effects. Here, the first principal axis,
PC1, is mostly aligned with the experimental covariate of interest 
(untreated / treated), while the second axis is roughly aligned with 
the sequencing protocol (single-read / paired-end). We used a data
transformation, the regularized logarithm or ``rlog``. Instead of PCA, other 
ordination methods, for instance multi-dimensional scaling, can also be useful,
we will see these in some of our followup lectures.


### Heatmaps

Heatmaps can be a powerful way of quickly getting an overview over a matrix-like 
dataset, count tables included. Below you see how to make a heatmap from the 
rlog- transformed data. For a matrix as large as counts(pasilla), it is not 
practical to plot all of it, so we plot the subset of the 30 most variable 
genes.

```{r figHeatmap, fig.width = 4, fig.height = 6}
library("pheatmap")
select = order(rowMeans(assay(pas_rlog)), decreasing = TRUE)[1:30]
pheatmap(
  assay(pas_rlog)[select, ],
  scale = "row",
  annotation_col = as.data.frame(colData(pas_rlog)[, c("condition", "type")]))
```


If you want, you can try a different heatmap package (for example "ComplexHeatmap")
and explore a more enriched heatmap plot.

```{r}
# BiocManager::install("ComplexHeatmap")
# library("ComplexHeatmap")
# TODO
```


## Two-factor analysis of the pasilla data

Besides the treatment with siRNA, the ``pasilla`` data have another covariate,
``type``, which indicates the type of sequencing that was performed.
We saw in the PCA plot that the sequencing ``type`` had a considerable 
systematic effect on the data. Our basic analysis did not take this account, 
but we will do so now. This should help us get a more correct picture of which
differences in the data are attributable to the treatment, and which are
confounded --or masked-- by the sequencing type.

```{r replaceDesign}
pasillaTwoFactor = pasilla
design(pasillaTwoFactor) = formula(~ type + condition)
pasillaTwoFactor = DESeq(pasillaTwoFactor)
```

Of the two variables ``type`` and ``condition``, the one of primary interest
is the latter, and in ``DESeq2``, the convention is to put it at the end of the
formula. This convention has no effect on the model fitting, but it helps 
simplify some of the subsequent results reporting. Again, we access the results 
using the
``results`` function.

```{r multiResults}
res2 = results(pasillaTwoFactor)
head(res2, n = 3)
```


It is also possible to retrieve the $\log_2$ fold changes, p-values and adjusted
p-values associated with the ``type`` variable.  The function ``results`` takes an
argument ``contrast`` that lets users specify the name of the variable, the level
that corresponds to the numerator of the fold change and the level that corresponds
to the denominator of the fold change.

```{r multiTypeResults}
resType = results(pasillaTwoFactor, 
                  contrast = c("type", "single-read", "paired-end"))
head(resType, n = 3)
```

So what did we gain from this analysis that took into account ``type`` as a 
nuisance factor (sometimes also called, more politely, a ``blocking factor``), 
compared to the simple comparison between two groups? Let us plot the
p-values from both analyses against each other.

```{r scpres1res2,  warning = FALSE}
trsf = function(x) ifelse(is.na(x), 0, (-log10(x)) ^ (1/6))
ggplot(tibble(pOne = res$pvalue,
              pTwo = res2$pvalue),
    aes(x = trsf(pOne), y = trsf(pTwo))) +
    geom_hex(bins = 75) + coord_fixed() +
    xlab("Single factor analysis (condition)") +
    ylab("Two factor analysis (type + condition)") +
    geom_abline(col = "orange")
```

Comparison of p-values from the models with a single factor (condition) and with
two factors (type + condition). The axes correspond to 
$(-\log_{10}p)^{\frac{1}{6}}$, an arbitrarily chosen monotonically decreasing 
transformation that compresses the dynamic range of the p-values for the purpose 
of visualization. We can see a trend for the joint distribution to lie above the
bisector, indicating that the p-values in the two-factor analysis are generally 
smaller than those in the one-factor analysis.

As we can see, the p-values in the two-factor analysis are similar to those 
from the one-factor analysis, but are generally smaller. The more sophisticated 
analysis has led to an, albeit modest, increase in power. We can also see this 
by counting the number of genes that pass a certain significance threshold in 
each case:

```{r compareRes}
compareRes = table(
   `simple analysis` = res$padj < 0.1,
   `two factor` = res2$padj < 0.1 )
addmargins( compareRes )
```

The two-factor analysis found `r sum(compareRes[,2])` genes differentially 
expressed at an FDR threshold of 10\%, while the one-factor analysis found 
`r sum(compareRes[2,])`. The two-factor analysis has increased detection power. 
In general, the gain can be even much larger, or also smaller, depending on the 
data. The proper choice of the model requires informed adaptation to the
experimental design and data quality.

 Why do we detect fewer significant genes when we do not take into account the
``type`` variable?  More generally, what does this mean about the benefit of 
taking into account (or not) blocking factors?

Without modeling the blocking factor, the variability in the data that is due 
to it has to be absorbed by the $\varepsilon$s. This means that they are 
generally larger than in the model with the blocking factor. The higher level
of noise leads to higher uncertainty in the $\beta$-estimates.  On the other 
hand, the model with the blocking factor has more parameters that need to be 
estimated. In statistical parlance, the fit has fewer ``degrees of freedom''.  
Both of these effects are counteracting, and which of them prevails, and which 
of the modeling choices yields more or fewer significant results depends 
on the data.
  
As a note of caution: The two p-values calculated above (one with ~condition
and one with ~type+condition) correspond to different null hypotheses. This 
can be a problem when the blocking factor and condition are correlated.

